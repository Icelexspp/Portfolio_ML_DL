{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhSamPhp6MO4"
   },
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fok3vgDC6MO-"
   },
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## Pima Diabetes Dataset\n",
    "\n",
    "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEYQX9_x6MPA"
   },
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:32:45.531875Z",
     "start_time": "2023-07-11T05:32:42.812271Z"
    },
    "id": "akxqlJXD6MPB"
   },
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:32:47.462946Z",
     "start_time": "2023-07-11T05:32:45.533874Z"
    },
    "id": "QyKuA1RC6MPD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 12:35:47.139491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:32:47.557406Z",
     "start_time": "2023-07-11T05:32:47.466540Z"
    },
    "id": "LWpaUbkH6MPE"
   },
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
    "\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:32:49.054606Z",
     "start_time": "2023-07-11T05:32:49.013479Z"
    },
    "id": "5mdumeMO6MPE",
    "outputId": "f35bbe0e-b0f7-4e5d-8935-4bffb0f786c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.748</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.261</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.743</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "233               4                     122              68               0   \n",
       "6                 3                      78              50              32   \n",
       "565               2                      95              54              14   \n",
       "92                7                      81              78              40   \n",
       "164               0                     131              88               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "233        0  35.0              0.394   29             0  \n",
       "6         88  31.0              0.248   26             1  \n",
       "565       88  26.1              0.748   22             0  \n",
       "92        48  46.7              0.261   42             0  \n",
       "164        0  31.6              0.743   32             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:33:44.877226Z",
     "start_time": "2023-07-11T05:33:44.864626Z"
    },
    "id": "hf8sVSqC6MPG"
   },
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:33:45.355325Z",
     "start_time": "2023-07-11T05:33:45.339801Z"
    },
    "id": "QfywxD0u6MPG"
   },
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:33:45.910424Z",
     "start_time": "2023-07-11T05:33:45.898373Z"
    },
    "id": "If41o1lE6MPH",
    "outputId": "06399700-5fd1-48a9-dffa-595616e20973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPSGVR8V6MPH"
   },
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:42:37.518679Z",
     "start_time": "2023-07-11T05:42:37.215377Z"
    },
    "id": "O_QG0FhM6MPI",
    "outputId": "58ea3660-d322-4208-be14-5ce4c6c18700"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:42:37.750221Z",
     "start_time": "2023-07-11T05:42:37.708279Z"
    },
    "id": "mfyV3r3E6MPI",
    "outputId": "8788a1c5-e85e-469e-d633-b1fa8e284370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.824\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T05:44:40.351641Z",
     "start_time": "2023-07-11T05:44:40.191213Z"
    },
    "id": "r3LKQAKF6MPJ",
    "outputId": "5742ef07-58f7-44e5-fc9a-04d02e437ff3",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR6rckDt6MPJ"
   },
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:04:35.226051Z",
     "start_time": "2023-07-11T06:04:35.208044Z"
    },
    "id": "i8-B25f96MPJ"
   },
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:04:37.117197Z",
     "start_time": "2023-07-11T06:04:35.904229Z"
    },
    "id": "zHJv3reh6MPK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 12:35:53.039929: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the Model\n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "#HW ปรับจูน model ให้มีค่ามากกว่า accuracy is 0.766 ,roc-auc is 0.820 ที่เป็น model random forest\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:04:38.499019Z",
     "start_time": "2023-07-11T06:04:38.482331Z"
    },
    "id": "nYwbhd1Q6MPK",
    "outputId": "7e384e18-7d67-40f9-89ea-14f650f2f455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsmAQoop6MPL"
   },
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:09:00.570083Z",
     "start_time": "2023-07-11T06:08:43.391533Z"
    },
    "id": "j2OPvZXf6MPL",
    "outputId": "52f624c2-e4dd-4ce8-a991-edc4ce45f036",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.6627 - accuracy: 0.6163 - val_loss: 0.6555 - val_accuracy: 0.6615\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6250 - val_loss: 0.6486 - val_accuracy: 0.6615\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6389 - val_loss: 0.6421 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6458 - val_loss: 0.6362 - val_accuracy: 0.6771\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6562 - val_loss: 0.6306 - val_accuracy: 0.6875\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6632 - val_loss: 0.6254 - val_accuracy: 0.6927\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6719 - val_loss: 0.6206 - val_accuracy: 0.6771\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6840 - val_loss: 0.6160 - val_accuracy: 0.6875\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6910 - val_loss: 0.6117 - val_accuracy: 0.6979\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6962 - val_loss: 0.6077 - val_accuracy: 0.7083\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6979 - val_loss: 0.6039 - val_accuracy: 0.7135\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7118 - val_loss: 0.6002 - val_accuracy: 0.7135\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7135 - val_loss: 0.5968 - val_accuracy: 0.7188\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7205 - val_loss: 0.5936 - val_accuracy: 0.7188\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7222 - val_loss: 0.5904 - val_accuracy: 0.7240\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7188 - val_loss: 0.5874 - val_accuracy: 0.7240\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7222 - val_loss: 0.5845 - val_accuracy: 0.7240\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7205 - val_loss: 0.5818 - val_accuracy: 0.7292\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7240 - val_loss: 0.5791 - val_accuracy: 0.7396\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7274 - val_loss: 0.5766 - val_accuracy: 0.7448\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7378 - val_loss: 0.5742 - val_accuracy: 0.7448\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7396 - val_loss: 0.5718 - val_accuracy: 0.7448\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7431 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7465 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7483 - val_loss: 0.5653 - val_accuracy: 0.7448\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7448\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7483 - val_loss: 0.5615 - val_accuracy: 0.7448\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7465 - val_loss: 0.5596 - val_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7483 - val_loss: 0.5579 - val_accuracy: 0.7604\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7465 - val_loss: 0.5562 - val_accuracy: 0.7604\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7483 - val_loss: 0.5546 - val_accuracy: 0.7604\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7500 - val_loss: 0.5530 - val_accuracy: 0.7552\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7517 - val_loss: 0.5516 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7535 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7535 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7569 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7622 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7656 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7639 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7656 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7656 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7639 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7656 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7639 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7639 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7639 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7639 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7639 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7656 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7656 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7639 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7622 - val_loss: 0.5284 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.5250 - val_accuracy: 0.7292\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7292\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7656 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7656 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.5234 - val_accuracy: 0.7292\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7674 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7656 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7674 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7656 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7674 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7691 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7674 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7691 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7691 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7691 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7691 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7691 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7674 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7674 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7674 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7674 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7656 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7656 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7656 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7639 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7639 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7656 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7639 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7622 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7622 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7639 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7674 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7691 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7691 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7691 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7691 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7691 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7691 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7691 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7743 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7760 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7795 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7795 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7795 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(optimizer=SGD(learning_rate=0.005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, batch_size=32)\n",
    "# the fit function returns the run history.\n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:19:36.188504Z",
     "start_time": "2023-07-11T06:19:36.103815Z"
    },
    "id": "EbuQAekt6MPL",
    "outputId": "92c10fab-39e6-40d1-db21-1021e290ea0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 961us/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:20:10.190125Z",
     "start_time": "2023-07-11T06:20:10.175698Z"
    },
    "id": "kdiDtpz66MPM",
    "outputId": "dc90e6ea-fc65-4b56-ef2b-d8de976a4188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:20:13.947705Z",
     "start_time": "2023-07-11T06:20:13.932711Z"
    },
    "id": "p_pMftuE6MPM",
    "outputId": "f4a36a65-1f9d-4917-ccf1-39cfcb301022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48430583],\n",
       "       [0.71670175],\n",
       "       [0.40970513],\n",
       "       [0.32777134],\n",
       "       [0.22339405],\n",
       "       [0.49722183],\n",
       "       [0.02726596],\n",
       "       [0.29949844],\n",
       "       [0.93109757],\n",
       "       [0.15637484]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:21:26.851530Z",
     "start_time": "2023-07-11T06:21:26.728049Z"
    },
    "id": "4p-QbSBS6MPN",
    "outputId": "edfd372d-fc48-4bd2-8633-a9cb51fb0dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.808\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09YO67oi6MPN"
   },
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DXKoXVk6MPN"
   },
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:22:20.751717Z",
     "start_time": "2023-07-11T06:22:20.733576Z"
    },
    "id": "nvPNg3DV6MPO",
    "outputId": "5124113c-d96c-48c2-f47b-78cab5f08e5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hWqveXu6MPO"
   },
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:22:38.613059Z",
     "start_time": "2023-07-11T06:22:38.487649Z"
    },
    "id": "FpZYef1l6MPO",
    "outputId": "ccfd81e8-e8fb-430c-9e43-9b50e4049baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9772b45fc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTlbfgUP6MPP"
   },
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:24:33.799656Z",
     "start_time": "2023-07-11T06:23:18.012503Z"
    },
    "id": "W4tua7Om6MPP",
    "outputId": "4e93d023-20cd-40a9-b346-ac14af6b0712",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7795 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5140 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8038 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8038 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8021 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T06:24:34.018581Z",
     "start_time": "2023-07-11T06:24:33.802564Z"
    },
    "id": "RCbvO1Wm6MPP",
    "outputId": "82eb5da5-9918-46b6-822c-e4e1403f2896"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9772bf7a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlM_Ao-S6MPP"
   },
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dy7OG9Og6MPQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82INOw6f6MPQ"
   },
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Train your new model, here is a suggestion:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of 0.003 and train for 1500 epochs\n",
    "- Graph the trajectory of the values of loss and accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "You probably need to experiment with different learning rates, numbers of epochs, and network structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oopD8Lmc6MPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape= (6,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")    #output layer\n",
    "])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.compile(SGD(lr = 0.005), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.7060 - accuracy: 0.6042 - val_loss: 0.7064 - val_accuracy: 0.5781\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.6042 - val_loss: 0.6976 - val_accuracy: 0.5938\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6076 - val_loss: 0.6895 - val_accuracy: 0.5885\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6822 - accuracy: 0.6094 - val_loss: 0.6821 - val_accuracy: 0.5990\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.6076 - val_loss: 0.6752 - val_accuracy: 0.5938\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6094 - val_loss: 0.6689 - val_accuracy: 0.5938\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.6076 - val_loss: 0.6630 - val_accuracy: 0.5938\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6076 - val_loss: 0.6576 - val_accuracy: 0.5990\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6163 - val_loss: 0.6524 - val_accuracy: 0.5990\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6215 - val_loss: 0.6476 - val_accuracy: 0.6198\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6285 - val_loss: 0.6430 - val_accuracy: 0.6406\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6319 - val_loss: 0.6385 - val_accuracy: 0.6458\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6476 - val_loss: 0.6343 - val_accuracy: 0.6458\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6476 - val_loss: 0.6302 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6493 - val_loss: 0.6263 - val_accuracy: 0.6562\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6476 - val_loss: 0.6225 - val_accuracy: 0.6771\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6510 - val_loss: 0.6188 - val_accuracy: 0.6823\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6562 - val_loss: 0.6152 - val_accuracy: 0.6927\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6545 - val_loss: 0.6117 - val_accuracy: 0.6823\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6649 - val_loss: 0.6083 - val_accuracy: 0.6771\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6667 - val_loss: 0.6050 - val_accuracy: 0.6875\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6719 - val_loss: 0.6018 - val_accuracy: 0.6927\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6788 - val_loss: 0.5987 - val_accuracy: 0.7031\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6788 - val_loss: 0.5956 - val_accuracy: 0.7083\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.6823 - val_loss: 0.5926 - val_accuracy: 0.7031\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6875 - val_loss: 0.5896 - val_accuracy: 0.7083\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6875 - val_loss: 0.5868 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6910 - val_loss: 0.5840 - val_accuracy: 0.7135\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.6944 - val_loss: 0.5812 - val_accuracy: 0.7135\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.6962 - val_loss: 0.5786 - val_accuracy: 0.7135\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6997 - val_loss: 0.5759 - val_accuracy: 0.7188\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7066 - val_loss: 0.5733 - val_accuracy: 0.7188\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7083 - val_loss: 0.5708 - val_accuracy: 0.7240\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7153 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7170 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7153 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7153 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7170 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7188 - val_loss: 0.5566 - val_accuracy: 0.7292\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7205 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7257 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7274 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7326 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7361 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7396 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7413 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7396 - val_loss: 0.5407 - val_accuracy: 0.7448\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7413 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7448 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7431 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7431 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7413 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7396 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7413 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7465 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7431 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7500 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7500 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7500 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7517 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7587 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7552 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7604 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7604 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7604 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7622 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7587 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7604 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7604 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5060 - val_accuracy: 0.7760\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.5018 - val_accuracy: 0.7812\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7812\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7708 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7708 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7812\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7812\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7812\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7812\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7812\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7812\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7865\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7969\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7969\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7969\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7969\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4999 - val_accuracy: 0.7969\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7969\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7969\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7969\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7969\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7969\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7969\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7969\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7969\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7969\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7969\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7969\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7969\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7969\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7969\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7812\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7812\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7812\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7812\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7812\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7812\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7812\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7812\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7812\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7812\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5031 - val_accuracy: 0.7865\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7865\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7865\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7865\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7865\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7865\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7812\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5004 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7986 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8003 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8003 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8003 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8003 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8021 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8003 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8003 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4992 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.4949 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7934 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7934 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7917 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7917 - val_loss: 0.4912 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7760\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7760\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7760\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7760\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4909 - val_accuracy: 0.7760\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.4908 - val_accuracy: 0.7812\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7812\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7812\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7812\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7812\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7812\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7812\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7812\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7812\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7812\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7934 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.4900 - val_accuracy: 0.7812\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.4900 - val_accuracy: 0.7812\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7934 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.4897 - val_accuracy: 0.7812\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.4896 - val_accuracy: 0.7812\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7812\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7812\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7934 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7934 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7934 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7934 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.4887 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7917 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7812\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7812\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7812\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4864 - val_accuracy: 0.7812\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.4862 - val_accuracy: 0.7812\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7882 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7882 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7882 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7882 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.4854 - val_accuracy: 0.7812\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.4847 - val_accuracy: 0.7812\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.4847 - val_accuracy: 0.7812\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7812\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.4845 - val_accuracy: 0.7812\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.4843 - val_accuracy: 0.7812\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.4843 - val_accuracy: 0.7812\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.4842 - val_accuracy: 0.7812\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.4844 - val_accuracy: 0.7812\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4842 - val_accuracy: 0.7812\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7760\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7760\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.4842 - val_accuracy: 0.7812\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.4841 - val_accuracy: 0.7760\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7760\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7812\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7812\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.4839 - val_accuracy: 0.7812\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7812\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.4837 - val_accuracy: 0.7812\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7812\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.4834 - val_accuracy: 0.7812\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.4834 - val_accuracy: 0.7812\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7917 - val_loss: 0.4834 - val_accuracy: 0.7812\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.4834 - val_accuracy: 0.7812\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7882 - val_loss: 0.4834 - val_accuracy: 0.7812\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4833 - val_accuracy: 0.7812\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7917 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.4832 - val_accuracy: 0.7812\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7917 - val_loss: 0.4833 - val_accuracy: 0.7812\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.4831 - val_accuracy: 0.7812\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7917 - val_loss: 0.4831 - val_accuracy: 0.7812\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7812\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.4830 - val_accuracy: 0.7812\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7917 - val_loss: 0.4831 - val_accuracy: 0.7812\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7812\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7812\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7812\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7899 - val_loss: 0.4830 - val_accuracy: 0.7812\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7812\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7812\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7812\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.7812\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4828 - val_accuracy: 0.7812\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.4828 - val_accuracy: 0.7812\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.4825 - val_accuracy: 0.7812\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7812\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.4828 - val_accuracy: 0.7812\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.4825 - val_accuracy: 0.7812\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.4824 - val_accuracy: 0.7812\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.4824 - val_accuracy: 0.7812\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4823 - val_accuracy: 0.7812\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.4824 - val_accuracy: 0.7812\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7812\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.4823 - val_accuracy: 0.7812\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4823 - val_accuracy: 0.7812\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.4820 - val_accuracy: 0.7812\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4819 - val_accuracy: 0.7812\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.4818 - val_accuracy: 0.7812\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4820 - val_accuracy: 0.7812\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.4820 - val_accuracy: 0.7812\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.4819 - val_accuracy: 0.7812\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4822 - val_accuracy: 0.7812\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.4820 - val_accuracy: 0.7812\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7812\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.4820 - val_accuracy: 0.7812\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.4818 - val_accuracy: 0.7812\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.4818 - val_accuracy: 0.7812\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.4818 - val_accuracy: 0.7812\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.4817 - val_accuracy: 0.7812\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.4815 - val_accuracy: 0.7812\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.4812 - val_accuracy: 0.7812\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.4808 - val_accuracy: 0.7865\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.4808 - val_accuracy: 0.7865\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.4809 - val_accuracy: 0.7812\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.4808 - val_accuracy: 0.7812\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4807 - val_accuracy: 0.7812\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.4806 - val_accuracy: 0.7812\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4808 - val_accuracy: 0.7812\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4804 - val_accuracy: 0.7812\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4803 - val_accuracy: 0.7812\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4802 - val_accuracy: 0.7812\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4801 - val_accuracy: 0.7812\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.4797 - val_accuracy: 0.7812\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.4797 - val_accuracy: 0.7812\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.4800 - val_accuracy: 0.7812\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.4798 - val_accuracy: 0.7812\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.4796 - val_accuracy: 0.7812\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.4796 - val_accuracy: 0.7812\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.4793 - val_accuracy: 0.7812\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.4793 - val_accuracy: 0.7812\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4793 - val_accuracy: 0.7812\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4793 - val_accuracy: 0.7812\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.4796 - val_accuracy: 0.7812\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.4795 - val_accuracy: 0.7812\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.4794 - val_accuracy: 0.7812\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.4793 - val_accuracy: 0.7812\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.4789 - val_accuracy: 0.7812\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.4791 - val_accuracy: 0.7812\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.4793 - val_accuracy: 0.7760\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.4792 - val_accuracy: 0.7760\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.4790 - val_accuracy: 0.7812\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.4790 - val_accuracy: 0.7812\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.4789 - val_accuracy: 0.7760\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.4789 - val_accuracy: 0.7760\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.4792 - val_accuracy: 0.7760\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.4789 - val_accuracy: 0.7760\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7934 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7934 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.4781 - val_accuracy: 0.7760\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.4781 - val_accuracy: 0.7760\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.4782 - val_accuracy: 0.7760\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.4781 - val_accuracy: 0.7760\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.4781 - val_accuracy: 0.7760\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.4780 - val_accuracy: 0.7760\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.4780 - val_accuracy: 0.7760\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.4780 - val_accuracy: 0.7760\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8003 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7969 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.4781 - val_accuracy: 0.7708\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.4781 - val_accuracy: 0.7708\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7969 - val_loss: 0.4780 - val_accuracy: 0.7708\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7708\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.4779 - val_accuracy: 0.7708\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.4779 - val_accuracy: 0.7708\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.4778 - val_accuracy: 0.7708\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8003 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8003 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7969 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7969 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7708\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8003 - val_loss: 0.4781 - val_accuracy: 0.7708\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.4779 - val_accuracy: 0.7708\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7708\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7708\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.4773 - val_accuracy: 0.7708\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7708\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7708\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4773 - val_accuracy: 0.7708\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7708\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4772 - val_accuracy: 0.7708\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4771 - val_accuracy: 0.7708\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7708\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7708\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7969 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8003 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.4772 - val_accuracy: 0.7760\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.4772 - val_accuracy: 0.7760\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.4772 - val_accuracy: 0.7760\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.4777 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "run_hist_new = model_new.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 989us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_new.predict(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_new.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "accuracy is 0.776\n",
      "roc-auc is 0.839\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the roc curve for the predictions\n",
    "\n",
    "y_pred_prob_nn_2 = model_new.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = (y_pred_prob_nn_2 >= 0.5).astype('int32')\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9772e59990>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the trajectory of the values of loss and accuracy on both train and test set\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_new.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_new.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ให้ใช้ไฟล์ jupyter notebook ของงานเดิม (สัปดาห์ที่ 4) ที่เทรนโมเดล Deep Neural Networks เพื่อทำนายผู้ป่วยโรคเบาหวาน มาปรับแก้ให้เป็นไปตามข้อกำหนด\n",
    "\n",
    "    - ข้อกำหนด\n",
    "- ให้แสดง ค่าตัววัดต่าง ๆ และกราฟของโมเดลเดิม เพื่อใช้เป็น baseline ในการพัฒนาโมเดล\n",
    "- ปรับโมเดลโดยให้มีการใช้ Regularization และสามารถปรับโครงสร้างโมเดลและค่า Hyperparameters ได้ แต่ห้ามใช้ Early Stopping เพื่อให้ผลการทำนายดีขึ้น (ให้พิจารณาจากค่า accuracy)\n",
    "- หลังจากเทรนโมเดลใหม่ ให้แสดง ค่าตัววัดและกราฟของโมเดลใหม่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_implement = tf.keras.Sequential([\n",
    "\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6,input_shape = (6,), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "\n",
    "])\n",
    "model_implement.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_implement.compile(SGD(lr = 0.005, momentum=0.3, nesterov=False), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_implement.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 0.7921 - accuracy: 0.4444 - val_loss: 0.7155 - val_accuracy: 0.4323\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.5035 - val_loss: 0.6983 - val_accuracy: 0.4635\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.5330 - val_loss: 0.6847 - val_accuracy: 0.5104\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7175 - accuracy: 0.5590 - val_loss: 0.6732 - val_accuracy: 0.5417\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.6007 - val_loss: 0.6635 - val_accuracy: 0.6094\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.6024 - val_loss: 0.6555 - val_accuracy: 0.6406\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6163 - val_loss: 0.6485 - val_accuracy: 0.6615\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6285 - val_loss: 0.6424 - val_accuracy: 0.6927\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6354 - val_loss: 0.6375 - val_accuracy: 0.7344\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6302 - val_loss: 0.6332 - val_accuracy: 0.7344\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6632 - val_loss: 0.6295 - val_accuracy: 0.7240\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6719 - val_loss: 0.6258 - val_accuracy: 0.7240\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6510 - val_loss: 0.6228 - val_accuracy: 0.7188\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6562 - val_loss: 0.6201 - val_accuracy: 0.7135\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6649 - val_loss: 0.6177 - val_accuracy: 0.7240\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6962 - val_loss: 0.6150 - val_accuracy: 0.7292\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6684 - val_loss: 0.6128 - val_accuracy: 0.7292\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6719 - val_loss: 0.6106 - val_accuracy: 0.7448\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6875 - val_loss: 0.6086 - val_accuracy: 0.7448\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6979 - val_loss: 0.6066 - val_accuracy: 0.7344\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7031 - val_loss: 0.6044 - val_accuracy: 0.7188\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7049 - val_loss: 0.6023 - val_accuracy: 0.7240\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6736 - val_loss: 0.6007 - val_accuracy: 0.7292\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6944 - val_loss: 0.5989 - val_accuracy: 0.7292\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6927 - val_loss: 0.5974 - val_accuracy: 0.7292\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6840 - val_loss: 0.5955 - val_accuracy: 0.7344\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.7049 - val_loss: 0.5938 - val_accuracy: 0.7292\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6944 - val_loss: 0.5922 - val_accuracy: 0.7240\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6962 - val_loss: 0.5909 - val_accuracy: 0.7240\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7170 - val_loss: 0.5889 - val_accuracy: 0.7240\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7240 - val_loss: 0.5871 - val_accuracy: 0.7292\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6997 - val_loss: 0.5858 - val_accuracy: 0.7292\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6892 - val_loss: 0.5847 - val_accuracy: 0.7240\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.7240\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7049 - val_loss: 0.5819 - val_accuracy: 0.7292\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7135 - val_loss: 0.5806 - val_accuracy: 0.7292\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7135 - val_loss: 0.5795 - val_accuracy: 0.7344\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7170 - val_loss: 0.5777 - val_accuracy: 0.7344\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7083 - val_loss: 0.5764 - val_accuracy: 0.7396\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7066 - val_loss: 0.5755 - val_accuracy: 0.7396\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7101 - val_loss: 0.5745 - val_accuracy: 0.7448\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7135 - val_loss: 0.5732 - val_accuracy: 0.7448\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7170 - val_loss: 0.5722 - val_accuracy: 0.7448\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7101 - val_loss: 0.5713 - val_accuracy: 0.7448\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7135 - val_loss: 0.5702 - val_accuracy: 0.7448\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7118 - val_loss: 0.5692 - val_accuracy: 0.7396\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7135 - val_loss: 0.5680 - val_accuracy: 0.7448\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7240 - val_loss: 0.5665 - val_accuracy: 0.7448\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7257 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7188 - val_loss: 0.5639 - val_accuracy: 0.7448\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7083 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7049 - val_loss: 0.5619 - val_accuracy: 0.7500\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.7014 - val_loss: 0.5609 - val_accuracy: 0.7500\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7188 - val_loss: 0.5599 - val_accuracy: 0.7500\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7153 - val_loss: 0.5584 - val_accuracy: 0.7604\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7135 - val_loss: 0.5569 - val_accuracy: 0.7604\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7083 - val_loss: 0.5561 - val_accuracy: 0.7604\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7257 - val_loss: 0.5551 - val_accuracy: 0.7604\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7326 - val_loss: 0.5541 - val_accuracy: 0.7604\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7326 - val_loss: 0.5531 - val_accuracy: 0.7656\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7205 - val_loss: 0.5520 - val_accuracy: 0.7604\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7274 - val_loss: 0.5512 - val_accuracy: 0.7656\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7274 - val_loss: 0.5502 - val_accuracy: 0.7604\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7483 - val_loss: 0.5489 - val_accuracy: 0.7552\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7066 - val_loss: 0.5483 - val_accuracy: 0.7552\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7274 - val_loss: 0.5471 - val_accuracy: 0.7552\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7153 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7031 - val_loss: 0.5464 - val_accuracy: 0.7604\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7378 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7101 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7431 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7205 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7274 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7170 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7396 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7483 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7205 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7188 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7413 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7257 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7170 - val_loss: 0.5343 - val_accuracy: 0.7552\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7448 - val_loss: 0.5338 - val_accuracy: 0.7552\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7344 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7292 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7500 - val_loss: 0.5313 - val_accuracy: 0.7604\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7587 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7431 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7361 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7326 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7344 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7274 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7378 - val_loss: 0.5271 - val_accuracy: 0.7708\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7396 - val_loss: 0.5266 - val_accuracy: 0.7708\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7413 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7396 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7274 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7396 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7274 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7517 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7413 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7448 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7483 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7344 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7483 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7344 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7500 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7448 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7361 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7361 - val_loss: 0.5197 - val_accuracy: 0.7656\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7361 - val_loss: 0.5195 - val_accuracy: 0.7656\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7413 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7483 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7326 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7274 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7292 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7344 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7448 - val_loss: 0.5180 - val_accuracy: 0.7708\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7604 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7257 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7517 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7396 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7431 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7361 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7396 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7448 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7292 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7378 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7431 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7569 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7517 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7448 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7413 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7448 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7552 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7431 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7431 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7448 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7517 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7552 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7448 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7413 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7569 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7465 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7431 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7483 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7378 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7483 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7448 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7361 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7309 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7500 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7396 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7465 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7431 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7517 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7431 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7344 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7517 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7552 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7396 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7413 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7552 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7569 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7448 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7535 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7361 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7413 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7465 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7465 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7639 - val_loss: 0.5097 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7656 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7396 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7622 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7309 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7378 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7517 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7448 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7378 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7569 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7639 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7483 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7552 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7448 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7483 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7483 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7413 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7483 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7483 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7691 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7361 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7569 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7587 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7500 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7448 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7674 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7535 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7465 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7292 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7517 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7708 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7587 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7535 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7483 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7517 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7483 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7604 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7431 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7517 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7483 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7674 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7500 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7552 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7413 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7326 - val_loss: 0.5060 - val_accuracy: 0.7552\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7413 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7465 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7517 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7587 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7431 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7517 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7517 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7483 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7604 - val_loss: 0.5053 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7500 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7604 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7292 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7535 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7639 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7500 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7517 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7656 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7587 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7361 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7552 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7500 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7396 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7448 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7396 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7639 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7535 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7604 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7656 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7535 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7639 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7587 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7465 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7465 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7483 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7622 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7413 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7448 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7552 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7500 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7396 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7500 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7569 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7483 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7517 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7465 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7500 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7587 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7413 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7535 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7587 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7552 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7535 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7361 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7535 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7535 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7552 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7483 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7656 - val_loss: 0.5019 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7448 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7500 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7552 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7465 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7552 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7361 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7569 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7517 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7587 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7604 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7622 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7535 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7535 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7483 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7604 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7483 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7587 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7431 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7483 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7483 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7587 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7674 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7535 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7604 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7552 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7587 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7517 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7569 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7622 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7465 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7674 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7344 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7569 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7535 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7500 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7674 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7500 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7760 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7500 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7587 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7552 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7500 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7535 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7743 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7604 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7587 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7604 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7587 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7552 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7535 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7517 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7552 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7465 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7552 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7587 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7448 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7483 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7743 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7465 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7552 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7604 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7535 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7604 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7587 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7587 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7604 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7448 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7587 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7309 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7622 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7569 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7569 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7552 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7622 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7569 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7517 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7622 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7552 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7674 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7535 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7431 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7622 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7396\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7552 - val_loss: 0.4998 - val_accuracy: 0.7396\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7396\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7517 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7569 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7569 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7604 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7691 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7622 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7604 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7604 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7517 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7604 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7413 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7899 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7535 - val_loss: 0.5003 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7587 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7465 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7674 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7795 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7552 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7674 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7535 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7604 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7569 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7587 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7535 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7483 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7639 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7569 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7535 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7639 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7569 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7396 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7708 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7569 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7622 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7622 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7622 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7622 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7622 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7587 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7517 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7639 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7552 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7569 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7552 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7569 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7604 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7587 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7569 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7448 - val_loss: 0.4960 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7552 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7465 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7552 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7587 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7778 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7552 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7656 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7778 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7552 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7622 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7569 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7604 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7587 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7778 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7604 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7552 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7483 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7587 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7552 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7604 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7587 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7622 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7812 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7431 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7552 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7587 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7604 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7639 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7431 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7431 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7483 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7604 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7569 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7465 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7587 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7639 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7535 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7552 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7604 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7517 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7622 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7465 - val_loss: 0.4961 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7500 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7639 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7639 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7396 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7465 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7431 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7639 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7587 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7431 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7604 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7517 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7639 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7604 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7483 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7604 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7465 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7569 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7569 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7656 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7431 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7500 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7535 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7552 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7413 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7500 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7517 - val_loss: 0.4952 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7517 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7760 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7535 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7569 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7535 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7639 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7569 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7552 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7882 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7639 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7604 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7604 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7483 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7552 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7604 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7569 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7639 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7569 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7778 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7483 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7778 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7552 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7378 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7569 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7604 - val_loss: 0.4946 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7760 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7535 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7604 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7622 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7535 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7639 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7639 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7500 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7448 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7569 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7622 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7535 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7760 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7569 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7552 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7569 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7639 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7656 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7535 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7500 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7622 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7552 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7552 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7535 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7552 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7448 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7517 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7639 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7622 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7639 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7552 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7396\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7535 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7483 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7465 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7483 - val_loss: 0.4959 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7500 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7569 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7361 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7604 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7587 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7535 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7569 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7569 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7535 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7760 - val_loss: 0.4972 - val_accuracy: 0.7344\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7535 - val_loss: 0.4968 - val_accuracy: 0.7344\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7639 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7431 - val_loss: 0.4968 - val_accuracy: 0.7344\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8003 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7552 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7587 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7622 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7622 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7604 - val_loss: 0.4961 - val_accuracy: 0.7344\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7622 - val_loss: 0.4962 - val_accuracy: 0.7344\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7344\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7535 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7569 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7951 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7361 - val_loss: 0.4962 - val_accuracy: 0.7344\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7743 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7517 - val_loss: 0.4968 - val_accuracy: 0.7344\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7639 - val_loss: 0.4968 - val_accuracy: 0.7344\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7465 - val_loss: 0.4972 - val_accuracy: 0.7344\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7639 - val_loss: 0.4972 - val_accuracy: 0.7344\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7431 - val_loss: 0.4977 - val_accuracy: 0.7344\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7344\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.4974 - val_accuracy: 0.7344\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7535 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7760 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7674 - val_loss: 0.4975 - val_accuracy: 0.7344\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7622 - val_loss: 0.4969 - val_accuracy: 0.7344\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.4968 - val_accuracy: 0.7344\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7413 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7569 - val_loss: 0.4968 - val_accuracy: 0.7396\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7535 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7344\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7500 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7587 - val_loss: 0.4969 - val_accuracy: 0.7344\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7517 - val_loss: 0.4969 - val_accuracy: 0.7344\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7344\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7639 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7344\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7344\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7344\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7552 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7552 - val_loss: 0.4975 - val_accuracy: 0.7344\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7639 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7344\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7760 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7604 - val_loss: 0.4977 - val_accuracy: 0.7344\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7552 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7344\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7569 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7517 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7934 - val_loss: 0.4990 - val_accuracy: 0.7344\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7569 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7691 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7344\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7517 - val_loss: 0.4981 - val_accuracy: 0.7344\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7778 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7795 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7604 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7708 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7396\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7569 - val_loss: 0.4986 - val_accuracy: 0.7396\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7552 - val_loss: 0.4986 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7708 - val_loss: 0.4987 - val_accuracy: 0.7344\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7483 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7535 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7587 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7604 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7448 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7483 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7708 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4983 - val_accuracy: 0.7396\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7535 - val_loss: 0.4980 - val_accuracy: 0.7344\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7587 - val_loss: 0.4983 - val_accuracy: 0.7396\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7535 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7639 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7552 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7517 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7622 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7552 - val_loss: 0.4992 - val_accuracy: 0.7396\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7517 - val_loss: 0.4991 - val_accuracy: 0.7396\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7587 - val_loss: 0.4993 - val_accuracy: 0.7396\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7535 - val_loss: 0.4990 - val_accuracy: 0.7344\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7639 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7587 - val_loss: 0.4987 - val_accuracy: 0.7344\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7552 - val_loss: 0.4990 - val_accuracy: 0.7344\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.4992 - val_accuracy: 0.7344\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7587 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7569 - val_loss: 0.4997 - val_accuracy: 0.7344\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7569 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7604 - val_loss: 0.5001 - val_accuracy: 0.7344\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.5001 - val_accuracy: 0.7344\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7604 - val_loss: 0.4999 - val_accuracy: 0.7344\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7604 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7344\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7587 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7344\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7604 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7604 - val_loss: 0.4998 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7344\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7344\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7587 - val_loss: 0.4995 - val_accuracy: 0.7344\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7344\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7535 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7569 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7517 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7708 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7535 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7674 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7465 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7535 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7604 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7535 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7587 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7639 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7500 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7604 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7552 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7622 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7743 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7552 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.5007 - val_accuracy: 0.7396\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7622 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7656 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7587 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7691 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7569 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7569 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7517 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7778 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7552 - val_loss: 0.5032 - val_accuracy: 0.7344\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7500 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7569 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7587 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7691 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7552 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7639 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7569 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7517 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7465 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7604 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7431 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7535 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7483 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7535 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7552 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7569 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7500 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7587 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7639 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7413 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7708 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7535 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7656 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7535 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7569 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7500 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7604 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7604 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7517 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7517 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7639 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7587 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7587 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7587 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7552 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7604 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7622 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7691 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7535 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7691 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7292\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5032 - val_accuracy: 0.7344\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7604 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7500 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7500 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7535 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7726 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7569 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7587 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7535 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7535 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7656 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7587 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7604 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7587 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7622 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7569 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7483 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7691 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7847 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7517 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7760 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7639 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7569 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7587 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7708 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7604 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7569 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7535 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7639 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7778 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7639 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7778 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7604 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7639 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7587 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7500 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7674 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7622 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7535 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7344\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7517 - val_loss: 0.5036 - val_accuracy: 0.7344\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7569 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7639 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7344\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7292\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7344\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7344\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7344\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7344\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5034 - val_accuracy: 0.7344\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7344\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7587 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7344\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7674 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7639 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7604 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7535 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7604 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7552 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.5033 - val_accuracy: 0.7344\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7344\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7500 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7344\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7778 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7656 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7344\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7604 - val_loss: 0.5034 - val_accuracy: 0.7344\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7292\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7604 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7292\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7292\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7569 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7778 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 1395/1500\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8438"
     ]
    }
   ],
   "source": [
    "run_hist_implement = model_implement.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the roc curve for the predictions\n",
    "\n",
    "y_pred_prob_nn_2 = model_implement.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = (y_pred_prob_nn_2 >= 0.5).astype('int32')\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_new.history[\"accuracy\"], 'pink', marker='.', label=\"Train Accuracy\")\n",
    "ax.plot(run_hist_new.history[\"val_accuracy\"], 'green', marker='.', label=\"Validation Accuracy\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
